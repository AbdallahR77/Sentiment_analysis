{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Import "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:13:31.653696Z","iopub.status.busy":"2023-06-20T11:13:31.653092Z","iopub.status.idle":"2023-06-20T11:13:44.956773Z","shell.execute_reply":"2023-06-20T11:13:44.955501Z","shell.execute_reply.started":"2023-06-20T11:13:31.653659Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T21:18:01.926457Z","iopub.status.busy":"2023-06-20T21:18:01.925470Z","iopub.status.idle":"2023-06-20T21:18:01.948393Z","shell.execute_reply":"2023-06-20T21:18:01.946913Z","shell.execute_reply.started":"2023-06-20T21:18:01.926404Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# Importing the libraries needed\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import transformers\n","import json\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaModel, RobertaTokenizer\n","from sklearn.model_selection import train_test_split\n","import logging\n","import re\n","import string\n","import nltk\n","from torch import cuda\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","\n","logging.basicConfig(level=logging.ERROR)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:14:09.724679Z","iopub.status.busy":"2023-06-20T11:14:09.724234Z","iopub.status.idle":"2023-06-20T11:14:10.257300Z","shell.execute_reply":"2023-06-20T11:14:10.255527Z","shell.execute_reply.started":"2023-06-20T11:14:09.724640Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'stop_words' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2720437448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"]}],"source":["# stop_words = [ word for word in stop_words if word not in negation]"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:52:08.919635Z","iopub.status.busy":"2023-06-20T20:52:08.919231Z","iopub.status.idle":"2023-06-20T20:52:08.989221Z","shell.execute_reply":"2023-06-20T20:52:08.987917Z","shell.execute_reply.started":"2023-06-20T20:52:08.919594Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if cuda.is_available() else 'cpu'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Data explore"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:52:08.991629Z","iopub.status.busy":"2023-06-20T20:52:08.990625Z","iopub.status.idle":"2023-06-20T20:52:28.145370Z","shell.execute_reply":"2023-06-20T20:52:28.144272Z","shell.execute_reply.started":"2023-06-20T20:52:08.991583Z"},"trusted":true},"outputs":[],"source":["review_df = pd.read_csv(\"/kaggle/input/goodreads-books-reviews-290312/goodreads_train.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:52:28.148971Z","iopub.status.busy":"2023-06-20T20:52:28.148504Z","iopub.status.idle":"2023-06-20T20:52:28.173984Z","shell.execute_reply":"2023-06-20T20:52:28.173037Z","shell.execute_reply.started":"2023-06-20T20:52:28.148921Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>book_id</th>\n","      <th>review_id</th>\n","      <th>rating</th>\n","      <th>review_text</th>\n","      <th>date_added</th>\n","      <th>date_updated</th>\n","      <th>read_at</th>\n","      <th>started_at</th>\n","      <th>n_votes</th>\n","      <th>n_comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8842281e1d1347389f2ab93d60773d4d</td>\n","      <td>18245960</td>\n","      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n","      <td>5</td>\n","      <td>This is a special book. It started slow for ab...</td>\n","      <td>Sun Jul 30 07:44:10 -0700 2017</td>\n","      <td>Wed Aug 30 00:00:26 -0700 2017</td>\n","      <td>Sat Aug 26 12:05:52 -0700 2017</td>\n","      <td>Tue Aug 15 13:23:18 -0700 2017</td>\n","      <td>28</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8842281e1d1347389f2ab93d60773d4d</td>\n","      <td>16981</td>\n","      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n","      <td>3</td>\n","      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n","      <td>Mon Dec 05 10:46:44 -0800 2016</td>\n","      <td>Wed Mar 22 11:37:04 -0700 2017</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8842281e1d1347389f2ab93d60773d4d</td>\n","      <td>28684704</td>\n","      <td>2ede853b14dc4583f96cf5d120af636f</td>\n","      <td>3</td>\n","      <td>A fun, fast paced science fiction thriller. I ...</td>\n","      <td>Tue Nov 15 11:29:22 -0800 2016</td>\n","      <td>Mon Mar 20 23:40:27 -0700 2017</td>\n","      <td>Sat Mar 18 23:22:42 -0700 2017</td>\n","      <td>Fri Mar 17 23:45:40 -0700 2017</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8842281e1d1347389f2ab93d60773d4d</td>\n","      <td>27161156</td>\n","      <td>ced5675e55cd9d38a524743f5c40996e</td>\n","      <td>0</td>\n","      <td>Recommended reading to understand what is goin...</td>\n","      <td>Wed Nov 09 17:37:04 -0800 2016</td>\n","      <td>Wed Nov 09 17:38:20 -0800 2016</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8842281e1d1347389f2ab93d60773d4d</td>\n","      <td>25884323</td>\n","      <td>332732725863131279a8e345b63ac33e</td>\n","      <td>4</td>\n","      <td>I really enjoyed this book, and there is a lot...</td>\n","      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n","      <td>Mon Apr 25 09:31:23 -0700 2016</td>\n","      <td>Sun Jun 26 00:00:00 -0700 2016</td>\n","      <td>Sat May 28 00:00:00 -0700 2016</td>\n","      <td>9</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            user_id   book_id  \\\n","0  8842281e1d1347389f2ab93d60773d4d  18245960   \n","1  8842281e1d1347389f2ab93d60773d4d     16981   \n","2  8842281e1d1347389f2ab93d60773d4d  28684704   \n","3  8842281e1d1347389f2ab93d60773d4d  27161156   \n","4  8842281e1d1347389f2ab93d60773d4d  25884323   \n","\n","                          review_id  rating  \\\n","0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n","1  a5d2c3628987712d0e05c4f90798eb67       3   \n","2  2ede853b14dc4583f96cf5d120af636f       3   \n","3  ced5675e55cd9d38a524743f5c40996e       0   \n","4  332732725863131279a8e345b63ac33e       4   \n","\n","                                         review_text  \\\n","0  This is a special book. It started slow for ab...   \n","1  Recommended by Don Katz. Avail for free in Dec...   \n","2  A fun, fast paced science fiction thriller. I ...   \n","3  Recommended reading to understand what is goin...   \n","4  I really enjoyed this book, and there is a lot...   \n","\n","                       date_added                    date_updated  \\\n","0  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n","1  Mon Dec 05 10:46:44 -0800 2016  Wed Mar 22 11:37:04 -0700 2017   \n","2  Tue Nov 15 11:29:22 -0800 2016  Mon Mar 20 23:40:27 -0700 2017   \n","3  Wed Nov 09 17:37:04 -0800 2016  Wed Nov 09 17:38:20 -0800 2016   \n","4  Mon Apr 25 09:31:23 -0700 2016  Mon Apr 25 09:31:23 -0700 2016   \n","\n","                          read_at                      started_at  n_votes  \\\n","0  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n","1                             NaN                             NaN        1   \n","2  Sat Mar 18 23:22:42 -0700 2017  Fri Mar 17 23:45:40 -0700 2017       22   \n","3                             NaN                             NaN        5   \n","4  Sun Jun 26 00:00:00 -0700 2016  Sat May 28 00:00:00 -0700 2016        9   \n","\n","   n_comments  \n","0           1  \n","1           0  \n","2           0  \n","3           1  \n","4           1  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["review_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Drop the user_id, Book_id, review_id, date_added, date_updated, read_at, and started_at we don't need them in our pipline"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:53:10.550782Z","iopub.status.busy":"2023-06-20T20:53:10.550182Z","iopub.status.idle":"2023-06-20T20:53:12.839803Z","shell.execute_reply":"2023-06-20T20:53:12.838706Z","shell.execute_reply.started":"2023-06-20T20:53:10.550741Z"},"trusted":true},"outputs":[],"source":["# Drop Dubplicate rows\n","review_df.drop_duplicates(subset=['review_text'], inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:53:12.842478Z","iopub.status.busy":"2023-06-20T20:53:12.842060Z","iopub.status.idle":"2023-06-20T20:53:13.414429Z","shell.execute_reply":"2023-06-20T20:53:13.412671Z","shell.execute_reply.started":"2023-06-20T20:53:12.842438Z"},"trusted":true},"outputs":[{"ename":"KeyError","evalue":"\"['user_id' 'book_id' 'review_id' 'date_added' 'date_updated' 'read_at'\\n 'started_at'] not found in axis\"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/320608854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreview_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"book_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date_added\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date_updated\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read_at\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"started_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['user_id' 'book_id' 'review_id' 'date_added' 'date_updated' 'read_at'\\n 'started_at'] not found in axis\""]}],"source":["review_df.drop([\"user_id\", \"book_id\", \"review_id\", \"date_added\", \"date_updated\", \"read_at\", \"started_at\"], axis =1, inplace=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:52:30.687617Z","iopub.status.busy":"2023-06-20T20:52:30.687010Z","iopub.status.idle":"2023-06-20T20:52:30.703616Z","shell.execute_reply":"2023-06-20T20:52:30.702496Z","shell.execute_reply.started":"2023-06-20T20:52:30.687574Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rating</th>\n","      <th>review_text</th>\n","      <th>n_votes</th>\n","      <th>n_comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>This is a special book. It started slow for ab...</td>\n","      <td>28</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>Recommended by Don Katz. Avail for free in Dec...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>A fun, fast paced science fiction thriller. I ...</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>Recommended reading to understand what is goin...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I really enjoyed this book, and there is a lot...</td>\n","      <td>9</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>899995</th>\n","      <td>3</td>\n","      <td>3.5 stars. \\n Jenna is a popular YA author and...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>899996</th>\n","      <td>3</td>\n","      <td>This was a quick read for me. I have read a lo...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>899997</th>\n","      <td>4</td>\n","      <td>** spoiler alert ** \\n 3.5 stars. \\n This book...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>899998</th>\n","      <td>4</td>\n","      <td>** spoiler alert ** \\n Another fun read from M...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>899999</th>\n","      <td>3</td>\n","      <td>** spoiler alert ** \\n 3.5 stars \\n I liked it...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>890254 rows × 4 columns</p>\n","</div>"],"text/plain":["        rating                                        review_text  n_votes  \\\n","0            5  This is a special book. It started slow for ab...       28   \n","1            3  Recommended by Don Katz. Avail for free in Dec...        1   \n","2            3  A fun, fast paced science fiction thriller. I ...       22   \n","3            0  Recommended reading to understand what is goin...        5   \n","4            4  I really enjoyed this book, and there is a lot...        9   \n","...        ...                                                ...      ...   \n","899995       3  3.5 stars. \\n Jenna is a popular YA author and...        0   \n","899996       3  This was a quick read for me. I have read a lo...        1   \n","899997       4  ** spoiler alert ** \\n 3.5 stars. \\n This book...        1   \n","899998       4  ** spoiler alert ** \\n Another fun read from M...        0   \n","899999       3  ** spoiler alert ** \\n 3.5 stars \\n I liked it...        0   \n","\n","        n_comments  \n","0                1  \n","1                0  \n","2                0  \n","3                1  \n","4                1  \n","...            ...  \n","899995           0  \n","899996           1  \n","899997           0  \n","899998           0  \n","899999           0  \n","\n","[890254 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["review_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Show the rating distribustion "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:29.383032Z","iopub.status.busy":"2023-03-31T20:06:29.382196Z","iopub.status.idle":"2023-03-31T20:06:29.646669Z","shell.execute_reply":"2023-03-31T20:06:29.645636Z","shell.execute_reply.started":"2023-03-31T20:06:29.382995Z"},"trusted":true},"outputs":[],"source":["review_df.rating.value_counts().plot(kind=\"bar\", xlabel=\"rates\", ylabel=\"Frequency\", title=\"Rates Frequency\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<strong> from this figure we can see that the rates 0 and 1 is less frequency rather than other rates  </strong>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## the correlation between votes and n_comments and rates|"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:29.649341Z","iopub.status.busy":"2023-03-31T20:06:29.648241Z","iopub.status.idle":"2023-03-31T20:06:30.216776Z","shell.execute_reply":"2023-03-31T20:06:30.215719Z","shell.execute_reply.started":"2023-03-31T20:06:29.649300Z"},"trusted":true},"outputs":[],"source":["plt.title(\"n_comments dis\")\n","sns.histplot(data = review_df, x= 'n_comments', bins=40)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:30.220161Z","iopub.status.busy":"2023-03-31T20:06:30.218125Z","iopub.status.idle":"2023-03-31T20:06:30.247977Z","shell.execute_reply":"2023-03-31T20:06:30.246755Z","shell.execute_reply.started":"2023-03-31T20:06:30.220119Z"},"trusted":true},"outputs":[],"source":["review_df.n_comments.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:30.252045Z","iopub.status.busy":"2023-03-31T20:06:30.249550Z","iopub.status.idle":"2023-03-31T20:06:30.774760Z","shell.execute_reply":"2023-03-31T20:06:30.773660Z","shell.execute_reply.started":"2023-03-31T20:06:30.252004Z"},"trusted":true},"outputs":[],"source":["plt.title(\"n_votes dis\")\n","sns.histplot(data = review_df, x= 'n_votes', bins=40)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:30.778543Z","iopub.status.busy":"2023-03-31T20:06:30.778251Z","iopub.status.idle":"2023-03-31T20:06:30.809015Z","shell.execute_reply":"2023-03-31T20:06:30.806987Z","shell.execute_reply.started":"2023-03-31T20:06:30.778516Z"},"trusted":true},"outputs":[],"source":["review_df.n_votes.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**From this results n_votes and n_comments will not usefull for us**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-01T13:22:29.415698Z","iopub.status.busy":"2023-04-01T13:22:29.415332Z","iopub.status.idle":"2023-04-01T13:22:29.469745Z","shell.execute_reply":"2023-04-01T13:22:29.468744Z","shell.execute_reply.started":"2023-04-01T13:22:29.415662Z"},"trusted":true},"outputs":[],"source":["review_df.drop([\"n_comments\", \"n_votes\"], axis =1, inplace=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Take a Sample from the original data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:06:30.870032Z","iopub.status.busy":"2023-03-31T20:06:30.869639Z","iopub.status.idle":"2023-03-31T20:06:30.931962Z","shell.execute_reply":"2023-03-31T20:06:30.930934Z","shell.execute_reply.started":"2023-03-31T20:06:30.869995Z"},"trusted":true},"outputs":[],"source":["# review_df = review_df.sample(int(len(review_df) * 0.3), random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T20:07:16.691640Z","iopub.status.busy":"2023-03-31T20:07:16.690966Z","iopub.status.idle":"2023-03-31T20:07:16.961226Z","shell.execute_reply":"2023-03-31T20:07:16.953259Z","shell.execute_reply.started":"2023-03-31T20:07:16.691601Z"},"trusted":true},"outputs":[],"source":["review_df.rating.value_counts().plot(kind=\"bar\", xlabel=\"rates\", ylabel=\"Frequency\", title=\"Rates Frequency\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" <strong >fine tune code is from https://github.com/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb </strong>\n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Text preprocessing"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:54:18.016459Z","iopub.status.busy":"2023-06-20T20:54:18.015488Z","iopub.status.idle":"2023-06-20T20:54:21.147062Z","shell.execute_reply":"2023-06-20T20:54:21.146011Z","shell.execute_reply.started":"2023-06-20T20:54:18.016402Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b86b7fa8eb8942bfbd70ae6d71556807","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02797e9015924ecca4d89bded2977cdc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5375f929d5cc4f2c9129ab855d56067f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Defining some key variables that will be used later on in the training\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 4\n","# EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n","# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',  truncation=True, do_lower_case=True)\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:54:31.284153Z","iopub.status.busy":"2023-06-20T20:54:31.283733Z","iopub.status.idle":"2023-06-20T20:54:31.295182Z","shell.execute_reply":"2023-06-20T20:54:31.293951Z","shell.execute_reply.started":"2023-06-20T20:54:31.284117Z"},"trusted":true},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","negation_words = [\"didn\", \"weren\", \"doesn't\",\" hasn't\", \"couldn\",\n"," \"mustn't\", \"isn\", \"hadn't\", \"isn't\", \"wasn't\", \"mightn't\",\n"," \"couldn't\", \"needn't\", \"haven't\", \"shan't\", \"wouldn't\",\n"," \"not\", \"no\", \"never\", \"none\", \"nobody\", \"nowhere\", \"nothing\",\"isn'\", \"'t\",\n"," \"shouldn't\", \"aren't\", \"didn't\", \"didn'\", \"don't\", \"hadn't\", \"won't\", \"wasn\", \"hadn\"]\n","stop_words = [ word for word in stop_words if word not in negation_words]\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:55:31.369681Z","iopub.status.busy":"2023-06-20T20:55:31.369033Z","iopub.status.idle":"2023-06-20T20:55:31.395658Z","shell.execute_reply":"2023-06-20T20:55:31.394367Z","shell.execute_reply.started":"2023-06-20T20:55:31.369634Z"},"trusted":true},"outputs":[],"source":["class SentimentData(Dataset):\n","    def __init__(self, dataframe_input, tokenizer, max_len, stop_wrods, negation_words, data_type=\"train\"):\n","        self.tokenizer = tokenizer\n","        self.data_type = data_type\n","        self.data = dataframe_input\n","        self.text = dataframe_input.review_text.values\n","        self.stop_wrods = stop_wrods\n","        self.negation_words = negation_words\n","\n","        if data_type != \"train\":\n","            self.review_id = self.data.review_id.values\n","\n","        if data_type == \"train\":\n","            self.targets = self.data.rating\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","    \n","    def preprocess_text(self, text):\n","        # Remove unnecessary white spaces\n","        text = \" \".join(text.split())\n","\n","        # Remove HTML tags\n","        text = re.sub('<[^<]+?>', '', text)\n","\n","        # Remove URLs\n","        text = re.sub(r'http\\S+', '', text)\n","\n","        # Convert to lowercase\n","        text = text.lower()\n","\n","        # Remove punctuation\n","        text = text.translate(str.maketrans('', '', string.punctuation))\n","         \n","        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","        \n","        splited_text = text.split()\n","        cleaned_text = []\n","        for word in splited_text:\n","            if word not in self.stop_wrods:\n","                cleaned_text.append(word)\n","            elif word in self.negation_words:\n","                cleaned_text.append(\"not\")\n","        text  = \" \".join(cleaned_text)\n","\n","\n","#         Tokenize the text\n","#         tokens = tokenizer.tokenize(text)\n","\n","#         Remove stopwords\n","#         c\n","#         tokens = [word for word in tokens if not word in stop_words]\n","\n","#         Lemmatize the tokens\n","#         lemmatizer = WordNetLemmatizer()\n","#         tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","\n","#         Join the tokens back into a string\n","#         preprocessed_text = ' '.join(tokens)\n","\n","        return text\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = self.preprocess_text(text)\n","        \n","               \n","        # Replace Negation words with [Not] Token\n","#         for i in range(len(tokens)):\n","#             sub_tokens = tokens[i].split('Ġ')\n","#             for j in range(len(sub_tokens)):\n","#                 if sub_tokens[j] in negation_words:\n","#                     sub_tokens[j] = '[NOT]'\n","#             tokens[i] = 'Ġ'.join(sub_tokens)\n","\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        \n","        if self.data_type == \"train\":\n","             return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets':  torch.tensor(self.targets[index], dtype=torch.float)\n","\n","        }\n","\n","        else:\n","             return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'review_id' : self.review_id[index]\n","                }"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-03-29T21:36:48.169703Z","iopub.status.busy":"2023-03-29T21:36:48.168381Z","iopub.status.idle":"2023-03-29T21:36:48.177088Z","shell.execute_reply":"2023-03-29T21:36:48.176334Z","shell.execute_reply.started":"2023-03-29T21:36:48.169644Z"}},"source":["## Train Test Split"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:55:36.368115Z","iopub.status.busy":"2023-06-20T20:55:36.367384Z","iopub.status.idle":"2023-06-20T20:55:36.792066Z","shell.execute_reply":"2023-06-20T20:55:36.790833Z","shell.execute_reply.started":"2023-06-20T20:55:36.368048Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FULL Dataset: (890254, 4)\n","TRAIN Dataset: (801228, 4)\n","Valid Dataset: (44513, 4)\n","TEST Dataset: (44513, 4)\n"]}],"source":["X_train, X_test, _, _ = train_test_split(review_df, review_df, test_size=0.1, random_state=42)\n","X_valid, X_test, _, _ = train_test_split(X_test, X_test, test_size=0.5, random_state=42)\n","\n","X_train.reset_index(inplace=True, drop=True)\n","X_test.reset_index(inplace=True, drop=True)\n","X_valid.reset_index(inplace=True, drop=True)\n","\n","print(\"FULL Dataset: {}\".format(review_df.shape))\n","print(\"TRAIN Dataset: {}\".format(X_train.shape))\n","print(\"Valid Dataset: {}\".format(X_valid.shape))\n","print(\"TEST Dataset: {}\".format(X_test.shape))\n","\n","training_set = SentimentData(X_train, tokenizer, MAX_LEN, stop_words, negation_words )\n","validation_set = SentimentData(X_valid, tokenizer, MAX_LEN, stop_words, negation_words)\n","testing_set = SentimentData(X_test, tokenizer, MAX_LEN, stop_words, negation_words)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:55:40.289794Z","iopub.status.busy":"2023-06-20T20:55:40.289043Z","iopub.status.idle":"2023-06-20T20:55:40.297381Z","shell.execute_reply":"2023-06-20T20:55:40.295825Z","shell.execute_reply.started":"2023-06-20T20:55:40.289754Z"},"trusted":true},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2,\n","                'pin_memory':True\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2,\n","               'pin_memory':True\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","vlidation_loader = DataLoader(validation_set, **train_params)\n","\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:01.464377Z","iopub.status.busy":"2023-06-20T20:57:01.463920Z","iopub.status.idle":"2023-06-20T20:57:01.473743Z","shell.execute_reply":"2023-06-20T20:57:01.472523Z","shell.execute_reply.started":"2023-06-20T20:57:01.464340Z"},"trusted":true},"outputs":[],"source":["class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 6)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = RobertaClass()\n","model.to(device)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:44.532855Z","iopub.status.busy":"2023-06-20T20:57:44.532059Z","iopub.status.idle":"2023-06-20T20:57:44.550473Z","shell.execute_reply":"2023-06-20T20:57:44.549208Z","shell.execute_reply.started":"2023-06-20T20:57:44.532817Z"},"trusted":true},"outputs":[],"source":["counts = X_train.rating.value_counts()\n","class0 = counts[0]\n","class1 = counts[1]\n","class2 = counts[2]\n","class3 = counts[3]\n","class4 = counts[4]\n","class5 = counts[5]\n","\n","total = class0 + class1 + class1 + class2 + class3 + class4 + class5\n","\n","weight_for_0 = (1 / class0) * (total / 2.0)\n","weight_for_1 = (1 / class1) * (total / 2.0)\n","weight_for_2 = (1 / class2) * (total / 2.0)\n","weight_for_3 = (1 / class3) * (total / 2.0)\n","weight_for_4 = (1 / class4) * (total / 2.0)\n","weight_for_5 = (1 / class5) * (total / 2.0)\n","\n","class_w = [weight_for_0, weight_for_1, weight_for_2, weight_for_3, weight_for_4, weight_for_5]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:45.160003Z","iopub.status.busy":"2023-06-20T20:57:45.159613Z","iopub.status.idle":"2023-06-20T20:57:45.169536Z","shell.execute_reply":"2023-06-20T20:57:45.168367Z","shell.execute_reply.started":"2023-06-20T20:57:45.159968Z"},"trusted":true},"outputs":[],"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss(weight =  torch.FloatTensor(class_w).to(device))\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:45.726983Z","iopub.status.busy":"2023-06-20T20:57:45.726201Z","iopub.status.idle":"2023-06-20T20:57:45.735208Z","shell.execute_reply":"2023-06-20T20:57:45.734223Z","shell.execute_reply.started":"2023-06-20T20:57:45.726945Z"},"trusted":true},"outputs":[],"source":["def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:49.560255Z","iopub.status.busy":"2023-06-20T20:57:49.559852Z","iopub.status.idle":"2023-06-20T20:57:49.572649Z","shell.execute_reply":"2023-06-20T20:57:49.571555Z","shell.execute_reply.started":"2023-06-20T20:57:49.560221Z"},"trusted":true},"outputs":[],"source":["# Defining the training function on the 80% of the dataset for tuning the distilbert model\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in tqdm(enumerate(training_loader, 0)):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(ids, mask, token_type_ids)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accuracy(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","        \n","        if _%5000==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 5000 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T20:57:54.173066Z","iopub.status.busy":"2023-06-20T20:57:54.172471Z","iopub.status.idle":"2023-06-20T20:57:54.785798Z","shell.execute_reply":"2023-06-20T20:57:54.784131Z","shell.execute_reply.started":"2023-06-20T20:57:54.173028Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2345: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2345: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","0it [00:00, ?it/s]\n"]},{"ename":"TypeError","evalue":"forward() got an unexpected keyword argument 'token_type_ids'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1476884055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/3468267754.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/213581073.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'token_type_ids'"]}],"source":["EPOCHS = 1\n","for epoch in range(EPOCHS):\n","    train(epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizer.save_pretrained(\"./tokinizer3\")\n","\n","# print('All files saved')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Submmetion"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["new_tokenizer = RobertaTokenizer.from_pretrained('/kaggle/working/tokinizer2')\n","model.load_state_dict(torch.load('/kaggle/working/model_RoBERTa2.pt'))\n","model.to(\"cpu\")"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:30:04.207490Z","iopub.status.busy":"2023-06-20T11:30:04.206563Z","iopub.status.idle":"2023-06-20T11:30:05.833193Z","shell.execute_reply":"2023-06-20T11:30:05.831994Z","shell.execute_reply.started":"2023-06-20T11:30:04.207449Z"},"trusted":true},"outputs":[],"source":["quantized_model = torch.quantization.quantize_dynamic(\n","    model, {torch.nn.Linear}, dtype=torch.qint8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["quantized_model"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:17:00.409850Z","iopub.status.busy":"2023-06-20T11:17:00.409225Z","iopub.status.idle":"2023-06-20T11:17:06.424580Z","shell.execute_reply":"2023-06-20T11:17:06.423428Z","shell.execute_reply.started":"2023-06-20T11:17:00.409809Z"},"trusted":true},"outputs":[],"source":["final_test = pd.read_csv(\"/kaggle/input/goodreads-books-reviews-290312/goodreads_test.csv\")\n","final_test.drop([\"user_id\", \"book_id\", \"date_added\", \"date_updated\", \"read_at\", \"started_at\", \"n_comments\", \"n_votes\"], axis =1, inplace=True)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:16:51.228124Z","iopub.status.busy":"2023-06-20T11:16:51.227443Z","iopub.status.idle":"2023-06-20T11:16:51.313662Z","shell.execute_reply":"2023-06-20T11:16:51.312603Z","shell.execute_reply.started":"2023-06-20T11:16:51.228079Z"},"trusted":true},"outputs":[],"source":["final_test.drop(final_test[1:].index.values, inplace =True)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:16:51.462166Z","iopub.status.busy":"2023-06-20T11:16:51.461670Z","iopub.status.idle":"2023-06-20T11:16:51.469833Z","shell.execute_reply":"2023-06-20T11:16:51.468613Z","shell.execute_reply.started":"2023-06-20T11:16:51.462129Z"},"trusted":true},"outputs":[],"source":["final_test.loc[0,\"review_text\"]= \"I don't hate\" "]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:17:06.427263Z","iopub.status.busy":"2023-06-20T11:17:06.426825Z","iopub.status.idle":"2023-06-20T11:17:06.440891Z","shell.execute_reply":"2023-06-20T11:17:06.439575Z","shell.execute_reply.started":"2023-06-20T11:17:06.427211Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>review_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n","      <td>** spoiler alert ** \\n This is definitely one ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n","      <td>** spoiler alert ** \\n \"You are what you drink...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dce649b733c153ba5363a0413cac988f</td>\n","      <td>Roar is one of my favorite characters in Under...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n","      <td>** spoiler alert ** \\n If you feel like travel...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>d11d3091e22f1cf3cb865598de197599</td>\n","      <td>3.5 stars \\n I read and enjoyed the first two ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>478028</th>\n","      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n","      <td>Can't wait for Travis' POV \\n Travis Before Ab...</td>\n","    </tr>\n","    <tr>\n","      <th>478029</th>\n","      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n","      <td>Had this on my to-read shelf forever. Will upd...</td>\n","    </tr>\n","    <tr>\n","      <th>478030</th>\n","      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n","      <td>The last book left me wanting for more. I need...</td>\n","    </tr>\n","    <tr>\n","      <th>478031</th>\n","      <td>8be463fed78f0da63e964706f710332b</td>\n","      <td>Things are heating up in the second novel of I...</td>\n","    </tr>\n","    <tr>\n","      <th>478032</th>\n","      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n","      <td>Before I even start this review, I must say th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>478033 rows × 2 columns</p>\n","</div>"],"text/plain":["                               review_id  \\\n","0       5c4df7e70e9b438c761f07a4620ccb7c   \n","1       8eaeaf13213eeb16ad879a2a2591bbe5   \n","2       dce649b733c153ba5363a0413cac988f   \n","3       8a46df0bb997269d6834f9437a4b0a77   \n","4       d11d3091e22f1cf3cb865598de197599   \n","...                                  ...   \n","478028  0e1db3d4b04256f9660f5d276ddf1314   \n","478029  0b7f352e58caf0fd1f961e98ef04e89c   \n","478030  9b19eff33ddb14e9e68fca2e90379e46   \n","478031  8be463fed78f0da63e964706f710332b   \n","478032  62ed1263c7d216986cc419cd4e8a408b   \n","\n","                                              review_text  \n","0       ** spoiler alert ** \\n This is definitely one ...  \n","1       ** spoiler alert ** \\n \"You are what you drink...  \n","2       Roar is one of my favorite characters in Under...  \n","3       ** spoiler alert ** \\n If you feel like travel...  \n","4       3.5 stars \\n I read and enjoyed the first two ...  \n","...                                                   ...  \n","478028  Can't wait for Travis' POV \\n Travis Before Ab...  \n","478029  Had this on my to-read shelf forever. Will upd...  \n","478030  The last book left me wanting for more. I need...  \n","478031  Things are heating up in the second novel of I...  \n","478032  Before I even start this review, I must say th...  \n","\n","[478033 rows x 2 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["final_test"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:18:53.175719Z","iopub.status.busy":"2023-06-20T11:18:53.175329Z","iopub.status.idle":"2023-06-20T11:18:53.183159Z","shell.execute_reply":"2023-06-20T11:18:53.181896Z","shell.execute_reply.started":"2023-06-20T11:18:53.175684Z"},"trusted":true},"outputs":[],"source":["final_test_set = SentimentData(final_test, new_tokenizer, MAX_LEN, stop_words, negation_words, \"test\")\n","test_params = {'batch_size': 32,\n","                'shuffle': False,\n","                'num_workers': 2,\n","               'pin_memory':True\n","                }\n","\n","final_test_set = DataLoader(final_test_set, **test_params)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:18:53.863346Z","iopub.status.busy":"2023-06-20T11:18:53.862165Z","iopub.status.idle":"2023-06-20T11:18:53.869123Z","shell.execute_reply":"2023-06-20T11:18:53.867895Z","shell.execute_reply.started":"2023-06-20T11:18:53.863301Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:30:22.482830Z","iopub.status.busy":"2023-06-20T11:30:22.481834Z","iopub.status.idle":"2023-06-20T11:30:22.493930Z","shell.execute_reply":"2023-06-20T11:30:22.492696Z","shell.execute_reply.started":"2023-06-20T11:30:22.482764Z"},"trusted":true},"outputs":[],"source":["def final_submmit(model, testing_loader):\n","    device = 'cpu'\n","    prediction_ids = []\n","    preds = []\n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for _, data in tqdm(enumerate(testing_loader, 0)):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","            review_id = data[\"review_id\"]\n","            outputs = model(ids, mask, token_type_ids)\n","            softmax_output = F.softmax(outputs, dim=1)\n","            predicted_classes = torch.argmax(softmax_output, dim=1)\n","            prediction_ids.extend(review_id)\n","            preds.extend(predicted_classes.cpu().numpy())\n","\n","        df = pd.DataFrame({'review_id': prediction_ids , \"rating\": preds })\n","        return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_submmit = final_submmit(quantized_model, final_test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-20T11:20:20.239787Z","iopub.status.idle":"2023-06-20T11:20:20.240676Z","shell.execute_reply":"2023-06-20T11:20:20.240435Z","shell.execute_reply.started":"2023-06-20T11:20:20.240407Z"},"trusted":true},"outputs":[],"source":["final_submmit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T13:22:51.649401Z","iopub.status.busy":"2023-06-03T13:22:51.648727Z","iopub.status.idle":"2023-06-03T13:22:51.656688Z","shell.execute_reply":"2023-06-03T13:22:51.655344Z","shell.execute_reply.started":"2023-06-03T13:22:51.649356Z"},"trusted":true},"outputs":[],"source":["final_submmit.to_csv(\"submmesion2.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T13:22:20.828525Z","iopub.status.busy":"2023-06-03T13:22:20.827493Z","iopub.status.idle":"2023-06-03T13:22:21.569006Z","shell.execute_reply":"2023-06-03T13:22:21.567868Z","shell.execute_reply.started":"2023-06-03T13:22:20.828481Z"},"trusted":true},"outputs":[],"source":["d = pd.read_csv(\"/kaggle/input/goodreads-books-reviews-290312/goodreads_sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:09:19.848501Z","iopub.status.busy":"2023-03-31T01:09:19.847961Z","iopub.status.idle":"2023-03-31T01:09:19.870084Z","shell.execute_reply":"2023-03-31T01:09:19.869091Z","shell.execute_reply.started":"2023-03-31T01:09:19.848451Z"},"trusted":true},"outputs":[],"source":["0.88 0.4 0.2 0.2 0.2 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","negation_words = [\"didn\", \"weren\", \"doesn't\",\" hasn't\", \"couldn\",\n"," \"mustn't\", \"isn\", \"hadn't\", \"isn't\", \"wasn't\", \"mightn't\",\n"," \"couldn't\", \"needn't\", \"haven't\", \"shan't\", \"wouldn't\",\n"," \"not\", \"no\", \"never\", \"none\", \"nobody\", \"nowhere\", \"nothing\",\"isn'\", \"'t\",\n"," \"shouldn't\", \"aren't\", \"didn't\", \"didn'\", \"don't\", \"hadn't\", \"won't\", \"wasn\", \"hadn\"]\n","stop_words = [ word for word in stop_words if word not in negation_words]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:27:16.842229Z","iopub.status.busy":"2023-06-03T15:27:16.841079Z","iopub.status.idle":"2023-06-03T15:27:16.858732Z","shell.execute_reply":"2023-06-03T15:27:16.857397Z","shell.execute_reply.started":"2023-06-03T15:27:16.842184Z"},"trusted":true},"outputs":[],"source":["class Senti_Toknizer():\n","    def __init__(self, tokenizer, stop_wrods, negation_words, max_len=256):\n","        self.tokenizer = tokenizer\n","        self.stop_wrods = stop_wrods\n","        self.negation_words = negation_words\n","        self.max_len = max_len\n","        \n","    def preprocess_text(self, text):\n","        # Remove unnecessary white spaces\n","        text = \" \".join(text.split())\n","\n","        # Remove HTML tags\n","        text = re.sub('<[^<]+?>', '', text)\n","\n","        # Remove URLs\n","        text = re.sub(r'http\\S+', '', text)\n","\n","        # Convert to lowercase\n","        text = text.lower()\n","\n","        # Remove punctuation\n","        text = text.translate(str.maketrans('', '', string.punctuation))\n","         \n","        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","        splited_text = text.split()\n","        cleaned_text = []\n","        for word in splited_text:\n","            if word not in self.stop_wrods:\n","                cleaned_text.append(word)\n","            elif word in self.negation_words:\n","                cleaned_text.append(\"not\")\n","        text  = \" \".join(cleaned_text)\n","        return text\n","\n","    def toknize(self, text):\n","        text = self.preprocess_text(text)\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        \n","        return {\n","        'ids': torch.tensor(ids, dtype=torch.long),\n","        'mask': torch.tensor(mask, dtype=torch.long),\n","        'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:27:17.378027Z","iopub.status.busy":"2023-06-03T15:27:17.377067Z","iopub.status.idle":"2023-06-03T15:27:17.383047Z","shell.execute_reply":"2023-06-03T15:27:17.381854Z","shell.execute_reply.started":"2023-06-03T15:27:17.377987Z"},"trusted":true},"outputs":[],"source":["g = Senti_Toknizer( new_tokenizer, stop_words, negation_words,)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:47:04.523412Z","iopub.status.busy":"2023-06-03T15:47:04.522708Z","iopub.status.idle":"2023-06-03T15:47:04.529922Z","shell.execute_reply":"2023-06-03T15:47:04.528595Z","shell.execute_reply.started":"2023-06-03T15:47:04.523372Z"},"trusted":true},"outputs":[],"source":["y = g.toknize(\"this book is not so good but the matrial of the paper is good over all this book is well made\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:47:04.844643Z","iopub.status.busy":"2023-06-03T15:47:04.843702Z","iopub.status.idle":"2023-06-03T15:47:04.871392Z","shell.execute_reply":"2023-06-03T15:47:04.870002Z","shell.execute_reply.started":"2023-06-03T15:47:04.844591Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    \n","    ids = y['ids'].to(device, dtype = torch.long).unsqueeze(0)\n","    mask = y['mask'].to(device, dtype = torch.long).unsqueeze(0)\n","    token_type_ids = y['token_type_ids'].to(device, dtype=torch.long).unsqueeze(0)  \n","    outputs = model(ids, mask, token_type_ids)\n","    \n","    softmax_output = F.softmax(outputs, dim=1)\n","\n","    N_propa = torch.sum(softmax_output[0,0:3]) \n","    P_propa = torch.sum(softmax_output[0,3:])\n","    \n","    print (f\"Positive probability {P_propa}, Negative Propability {N_propa}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:45:30.195298Z","iopub.status.busy":"2023-06-03T15:45:30.194256Z","iopub.status.idle":"2023-06-03T15:45:30.205650Z","shell.execute_reply":"2023-06-03T15:45:30.204215Z","shell.execute_reply.started":"2023-06-03T15:45:30.195245Z"},"trusted":true},"outputs":[],"source":["softmax_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:45:43.599896Z","iopub.status.busy":"2023-06-03T15:45:43.599451Z","iopub.status.idle":"2023-06-03T15:45:43.610050Z","shell.execute_reply":"2023-06-03T15:45:43.608691Z","shell.execute_reply.started":"2023-06-03T15:45:43.599858Z"},"trusted":true},"outputs":[],"source":["softmax_output[0,0:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:46:07.411274Z","iopub.status.busy":"2023-06-03T15:46:07.410880Z","iopub.status.idle":"2023-06-03T15:46:07.423226Z","shell.execute_reply":"2023-06-03T15:46:07.421734Z","shell.execute_reply.started":"2023-06-03T15:46:07.411237Z"},"trusted":true},"outputs":[],"source":["softmax_output[0,3:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T15:45:59.407354Z","iopub.status.busy":"2023-06-03T15:45:59.406351Z","iopub.status.idle":"2023-06-03T15:45:59.417059Z","shell.execute_reply":"2023-06-03T15:45:59.415810Z","shell.execute_reply.started":"2023-06-03T15:45:59.407313Z"},"trusted":true},"outputs":[],"source":["softmax_output"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:58:55.127133Z","iopub.status.busy":"2023-06-20T11:58:55.126088Z","iopub.status.idle":"2023-06-20T11:58:56.139478Z","shell.execute_reply":"2023-06-20T11:58:56.138134Z","shell.execute_reply.started":"2023-06-20T11:58:55.127079Z"},"trusted":true},"outputs":[],"source":["torch.save(quantized_model, 'qun_model_RoBERTa3w.pth')\n"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:58:57.927882Z","iopub.status.busy":"2023-06-20T11:58:57.926845Z","iopub.status.idle":"2023-06-20T11:58:58.690236Z","shell.execute_reply":"2023-06-20T11:58:58.689094Z","shell.execute_reply.started":"2023-06-20T11:58:57.927827Z"},"trusted":true},"outputs":[],"source":["c = torch.load('/kaggle/working/qun_model_RoBERTa3w.pth')"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T11:58:59.726378Z","iopub.status.busy":"2023-06-20T11:58:59.725125Z","iopub.status.idle":"2023-06-20T11:59:00.178388Z","shell.execute_reply":"2023-06-20T11:59:00.177070Z","shell.execute_reply.started":"2023-06-20T11:58:59.726332Z"},"trusted":true},"outputs":[{"data":{"text/plain":["RobertaClass(\n","  (l1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): DynamicQuantizedLinear(in_features=768, out_features=6, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["c"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["0.0001"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["1e-5 *10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
